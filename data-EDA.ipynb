{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distraction Driver Detection Project\n",
    "\n",
    "> In this notebook, We'll use the dataset which includes images of drivers while performing a number of tasks including drinking, texting etc. The aim is to correctly identify if the driver is distracted from driving. We might also like to check what activity the person is performing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook will be borken into the following steps:\n",
    "\n",
    "0. Import the Libraries.\n",
    "1. Import the Datasets.\n",
    "2. Create a vanilla CNN model.\n",
    "3. Create a vanilla CNN model with data augmentation.\n",
    "4. Train a CNN with Transfer Learning (VGG16).\n",
    "5. Kaggle Results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import random\n",
    "import time\n",
    "import tensorflow\n",
    "import datetime\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import FileLink\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "from IPython.display import display, Image\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Datasets\n",
    "\n",
    "We will import the `.csv` file to read the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_72999.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_25094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_92629.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject classname            img\n",
       "0    p002        c0  img_44733.jpg\n",
       "1    p002        c0  img_72999.jpg\n",
       "2    p002        c0  img_25094.jpg\n",
       "3    p002        c0  img_69092.jpg\n",
       "4    p002        c0  img_92629.jpg"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./state-farm-distracted-driver-detection/driver_imgs_list.csv')\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the csv file, We'll use the `classname` as the labels for the images and use the image names to match the labels with the correct images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Driver Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081'])\n"
     ]
    }
   ],
   "source": [
    "by_drivers = dataset.groupby('subject')\n",
    "unique_drivers = by_drivers.groups.keys()\n",
    "print(unique_drivers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 22424 total images.\n",
      "\n",
      "There are 17939 training images.\n",
      "There are 0 total training categories.\n",
      "There are 4485 validation images.\n",
      "There are 0 test images.\n"
     ]
    }
   ],
   "source": [
    "# Load the list of names\n",
    "names = [item[17:19] for item in sorted(glob(\"../state-farm-distracted-driver-detection/imgs/train/*/\"))]\n",
    "test_files_size = len(np.array(glob(os.path.join('..', 'state-farm-distracted-driver-detection/imgs', 'test', '*.jpg'))))\n",
    "x_train_size = len(x_train)\n",
    "categories_size = len(names)\n",
    "x_test_size = len(x_test)\n",
    "print('There are %s total images.\\n' % (test_files_size + x_train_size + x_test_size))\n",
    "print('There are %d training images.' % x_train_size)\n",
    "print('There are %d total training categories.' % categories_size)\n",
    "print('There are %d validation images.' % x_test_size)\n",
    "print('There are %d test images.'% test_files_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot figure size\n",
    "plt.figure(figsize = (10,10))\n",
    "# Count the number of images per category\n",
    "sns.countplot(x = 'classname', data = dataset)\n",
    "# Change the Axis names\n",
    "plt.ylabel('Count')\n",
    "plt.title('Categories Distribution')\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the frequency of images per driver\n",
    "drivers_id = pd.DataFrame((dataset['subject'].value_counts()).reset_index())\n",
    "drivers_id.columns = ['driver_id', 'Counts']\n",
    "drivers_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting class distribution\n",
    "dataset['class_type'] = dataset['classname'].str.extract('(\\d)',expand=False).astype(np.float)\n",
    "plt.figure(figsize = (20,20))\n",
    "dataset.hist('class_type', alpha=0.5, layout=(1,1), bins=10)\n",
    "plt.title('Class distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images overview\n",
    "\n",
    "Let's take a look at the various images in the dataset. I'll plot an image for each of the 10 classes. As the directory names are not descriptive, I'll use a map to define the title for each image that is more descriptive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_map = {'c0': 'Safe driving', \n",
    "                'c1': 'Texting - right', \n",
    "                'c2': 'Talking on the phone - right', \n",
    "                'c3': 'Texting - left', \n",
    "                'c4': 'Talking on the phone - left', \n",
    "                'c5': 'Operating the radio', \n",
    "                'c6': 'Drinking', \n",
    "                'c7': 'Reaching behind', \n",
    "                'c8': 'Hair and makeup', \n",
    "                'c9': 'Talking to passenger'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 20))\n",
    "image_count = 1\n",
    "BASE_URL = './state-farm-distracted-driver-detection/imgs/train/'\n",
    "for directory in os.listdir(BASE_URL):\n",
    "    if directory[0] != '.':\n",
    "        for i, file in enumerate(os.listdir(BASE_URL + directory)):\n",
    "            if i == 1:\n",
    "                break\n",
    "            else:\n",
    "                fig = plt.subplot(5, 2, image_count)\n",
    "                image_count += 1\n",
    "                image = mpimg.imread(BASE_URL + directory + '/' + file)\n",
    "                plt.imshow(image)\n",
    "                plt.title(activity_map[directory])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert image to grayscale and resize image to 64 * 64 pixels in 1 channel (grayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_CLASSES = 10\n",
    "# Color type: 1 - grey, 3 - rgb\n",
    "\n",
    "img_rows = 64\n",
    "img_cols = 64\n",
    "color_type = 1\n",
    "\n",
    "def get_cv2_image(path, img_rows, img_cols, color_type=3):\n",
    "    # Loading as Grayscale image\n",
    "    if color_type == 1:\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    elif color_type == 3:\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    # Reduce size\n",
    "    img = cv2.resize(img, (img_rows, img_cols)) \n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train data and using the validation approach, split the train data into 80% and 20% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def load_train(img_rows, img_cols, color_type=3):\n",
    "    start_time = time.time()\n",
    "    train_images = [] \n",
    "    train_labels = []\n",
    "    # Loop over the training folder \n",
    "    for classed in tqdm(range(NUMBER_CLASSES)):\n",
    "        print('Loading directory c{}'.format(classed))\n",
    "        files = glob(os.path.join('./state-farm-distracted-driver-detection/imgs/', 'train', 'c' + str(classed), '*.jpg'))\n",
    "        for file in files:\n",
    "            img = get_cv2_image(file, img_rows, img_cols, color_type)\n",
    "            train_images.append(img)\n",
    "            train_labels.append(classed)\n",
    "    print(\"Data Loaded in {} second\".format(time.time() - start_time))\n",
    "    return train_images, train_labels \n",
    "\n",
    "def read_and_normalize_train_data(img_rows, img_cols, color_type):\n",
    "    X, labels = load_train(img_rows, img_cols, color_type)\n",
    "    y = np_utils.to_categorical(labels, 10)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    x_train = np.array(x_train, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n",
    "    x_test = np.array(x_test, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load validation/test data from the test folder consisting of 72989 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Validation\n",
    "def load_test(size=200000, img_rows=64, img_cols=64, color_type=3):\n",
    "    path = os.path.join('.', 'state-farm-distracted-driver-detection/imgs/test', '*.jpg')\n",
    "    files = sorted(glob(path))\n",
    "    X_test, X_test_id = [], []\n",
    "    total = 0\n",
    "    files_size = len(files)\n",
    "    for file in tqdm(files):\n",
    "        if total >= size or total >= files_size:\n",
    "            break\n",
    "        file_base = os.path.basename(file)\n",
    "        img = get_cv2_image(file, img_rows, img_cols, color_type)\n",
    "        X_test.append(img)\n",
    "        X_test_id.append(file_base)\n",
    "        total += 1\n",
    "    return X_test, X_test_id\n",
    "\n",
    "def read_and_normalize_sampled_test_data(size, img_rows, img_cols, color_type=3):\n",
    "    test_data, test_ids = load_test(size, img_rows, img_cols, color_type)\n",
    "    \n",
    "    test_data = np.array(test_data, dtype=np.uint8)\n",
    "    test_data = test_data.reshape(-1,img_rows,img_cols,color_type)\n",
    "    \n",
    "    return test_data, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:04<00:39,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:08<00:33,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:12<00:29,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:16<00:24,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:20<00:20,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [00:24<00:16,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [00:28<00:12,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [00:32<00:07,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [00:35<00:03,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:39<00:00,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded in 39.32211899757385 second\n",
      "Train shape: (17939, 64, 64, 1)\n",
      "17939 train samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = read_and_normalize_train_data(img_rows, img_cols, color_type)\n",
    "print('Train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data augmentation configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1.0/255, \n",
    "                                   shear_range = 0.2, \n",
    "                                   zoom_range = 0.2, \n",
    "                                   horizontal_flip = True, \n",
    "                                   validation_split = 0.2)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/ 255, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17939\n",
      "4485\n"
     ]
    }
   ],
   "source": [
    "nb_train_samples = x_train.shape[0]\n",
    "nb_validation_samples = x_test.shape[0]\n",
    "\n",
    "print(nb_train_samples)\n",
    "print(nb_validation_samples)\n",
    "training_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "validation_generator = test_datagen.flow(x_test, y_test, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
